{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nilearn in /home/rubycheng/miniconda3/lib/python3.10/site-packages (0.10.0)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /home/rubycheng/miniconda3/lib/python3.10/site-packages (from nilearn) (1.10.0)\n",
      "Requirement already satisfied: pandas>=1.1.5 in /home/rubycheng/miniconda3/lib/python3.10/site-packages (from nilearn) (1.5.3)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /home/rubycheng/miniconda3/lib/python3.10/site-packages (from nilearn) (1.23.5)\n",
      "Requirement already satisfied: joblib>=1.0.0 in /home/rubycheng/miniconda3/lib/python3.10/site-packages (from nilearn) (1.1.1)\n",
      "Requirement already satisfied: scikit-learn>=1.0.0 in /home/rubycheng/miniconda3/lib/python3.10/site-packages (from nilearn) (1.2.1)\n",
      "Requirement already satisfied: requests>=2.25.0 in /home/rubycheng/miniconda3/lib/python3.10/site-packages (from nilearn) (2.28.1)\n",
      "Requirement already satisfied: nibabel>=3.2.0 in /home/rubycheng/miniconda3/lib/python3.10/site-packages (from nilearn) (5.0.1)\n",
      "Requirement already satisfied: lxml in /home/rubycheng/miniconda3/lib/python3.10/site-packages (from nilearn) (4.9.1)\n",
      "Requirement already satisfied: setuptools in /home/rubycheng/miniconda3/lib/python3.10/site-packages (from nibabel>=3.2.0->nilearn) (65.6.3)\n",
      "Requirement already satisfied: packaging>=17 in /home/rubycheng/miniconda3/lib/python3.10/site-packages (from nibabel>=3.2.0->nilearn) (23.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/rubycheng/miniconda3/lib/python3.10/site-packages (from pandas>=1.1.5->nilearn) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/rubycheng/miniconda3/lib/python3.10/site-packages (from pandas>=1.1.5->nilearn) (2022.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/rubycheng/miniconda3/lib/python3.10/site-packages (from requests>=2.25.0->nilearn) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/rubycheng/miniconda3/lib/python3.10/site-packages (from requests>=2.25.0->nilearn) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/rubycheng/miniconda3/lib/python3.10/site-packages (from requests>=2.25.0->nilearn) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/rubycheng/miniconda3/lib/python3.10/site-packages (from requests>=2.25.0->nilearn) (3.4)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/rubycheng/miniconda3/lib/python3.10/site-packages (from scikit-learn>=1.0.0->nilearn) (2.2.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/rubycheng/miniconda3/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas>=1.1.5->nilearn) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install nilearn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(b'Precentral_R',) (b'Frontal_Sup_L',) (b'Frontal_Sup_R',)\n",
      " (b'Frontal_Sup_Orb_L',) (b'Frontal_Sup_Orb_R',) (b'Frontal_Mid_L',)\n",
      " (b'Frontal_Mid_R',) (b'Frontal_Mid_Orb_L',) (b'Frontal_Mid_Orb_R',)\n",
      " (b'Frontal_Inf_Oper_L',) (b'Frontal_Inf_Oper_R',) (b'Frontal_Inf_Tri_L',)\n",
      " (b'Frontal_Inf_Tri_R',) (b'Frontal_Inf_Orb_L',) (b'Frontal_Inf_Orb_R',)\n",
      " (b'Rolandic_Oper_L',) (b'Rolandic_Oper_R',) (b'Supp_Motor_Area_L',)\n",
      " (b'Supp_Motor_Area_R',) (b'Olfactory_L',) (b'Olfactory_R',)\n",
      " (b'Frontal_Sup_Medial_L',) (b'Frontal_Sup_Medial_R',)\n",
      " (b'Frontal_Med_Orb_L',) (b'Frontal_Med_Orb_R',) (b'Rectus_L',)\n",
      " (b'Rectus_R',) (b'Insula_L',) (b'Insula_R',) (b'Cingulum_Ant_L',)\n",
      " (b'Cingulum_Ant_R',) (b'Cingulum_Mid_L',) (b'Cingulum_Mid_R',)\n",
      " (b'Cingulum_Post_L',) (b'Cingulum_Post_R',) (b'Hippocampus_L',)\n",
      " (b'Hippocampus_R',) (b'ParaHippocampal_L',) (b'ParaHippocampal_R',)\n",
      " (b'Amygdala_L',) (b'Amygdala_R',) (b'Calcarine_L',) (b'Calcarine_R',)\n",
      " (b'Cuneus_L',) (b'Cuneus_R',) (b'Lingual_L',) (b'Lingual_R',)\n",
      " (b'Occipital_Sup_L',) (b'Occipital_Sup_R',) (b'Occipital_Mid_L',)\n",
      " (b'Occipital_Mid_R',) (b'Occipital_Inf_L',) (b'Occipital_Inf_R',)\n",
      " (b'Fusiform_L',) (b'Fusiform_R',) (b'Postcentral_L',) (b'Postcentral_R',)\n",
      " (b'Parietal_Sup_L',) (b'Parietal_Sup_R',) (b'Parietal_Inf_L',)\n",
      " (b'Parietal_Inf_R',) (b'SupraMarginal_L',) (b'SupraMarginal_R',)\n",
      " (b'Angular_L',) (b'Angular_R',) (b'Precuneus_L',) (b'Precuneus_R',)\n",
      " (b'Paracentral_Lobule_L',) (b'Paracentral_Lobule_R',) (b'Caudate_L',)\n",
      " (b'Caudate_R',) (b'Putamen_L',) (b'Putamen_R',) (b'Pallidum_L',)\n",
      " (b'Pallidum_R',) (b'Thalamus_L',) (b'Thalamus_R',) (b'Heschl_L',)\n",
      " (b'Heschl_R',) (b'Temporal_Sup_L',) (b'Temporal_Sup_R',)\n",
      " (b'Temporal_Pole_Sup_L',) (b'Temporal_Pole_Sup_R',) (b'Temporal_Mid_L',)\n",
      " (b'Temporal_Mid_R',) (b'Temporal_Pole_Mid_L',) (b'Temporal_Pole_Mid_R',)\n",
      " (b'Temporal_Inf_L',) (b'Temporal_Inf_R',) (b'Cerebelum_Crus1_L',)\n",
      " (b'Cerebelum_Crus1_R',) (b'Cerebelum_Crus2_L',) (b'Cerebelum_Crus2_R',)\n",
      " (b'Cerebelum_3_L',) (b'Cerebelum_3_R',) (b'Cerebelum_4_5_L',)\n",
      " (b'Cerebelum_4_5_R',) (b'Cerebelum_6_L',) (b'Cerebelum_6_R',)\n",
      " (b'Cerebelum_7b_L',) (b'Cerebelum_7b_R',) (b'Cerebelum_8_L',)\n",
      " (b'Cerebelum_8_R',) (b'Cerebelum_9_L',) (b'Cerebelum_9_R',)\n",
      " (b'Cerebelum_10_L',) (b'Cerebelum_10_R',) (b'Vermis_1_2',) (b'Vermis_3',)\n",
      " (b'Vermis_4_5',) (b'Vermis_6',) (b'Vermis_7',) (b'Vermis_8',)\n",
      " (b'Vermis_9',) (b'Vermis_10',)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rubycheng/miniconda3/lib/python3.10/site-packages/numpy/lib/npyio.py:2520: VisibleDeprecationWarning: Reading unicode strings without specifying the encoding argument is deprecated. Set the encoding, use None for the system default.\n",
      "  output = genfromtxt(fname, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "from nilearn import datasets\n",
    "import numpy as np\n",
    "\n",
    "# Download the AAL atlas\n",
    "aal_atlas = datasets.fetch_atlas_aal(version='SPM12', verbose=1)\n",
    "\n",
    "# Access the atlas data and labels\n",
    "atlas_filename = aal_atlas.maps\n",
    "labels_filename = aal_atlas.labels\n",
    "\n",
    "# Load the atlas data and labels\n",
    "# Perform any further operations as needed\n",
    "# Load the labels\n",
    "labels = np.recfromcsv(labels_filename, delimiter='\\t')\n",
    "\n",
    "# Print the labels\n",
    "print(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rubycheng/miniconda3/lib/python3.10/site-packages/nilearn/input_data/__init__.py:23: FutureWarning: The import path 'nilearn.input_data' is deprecated in version 0.9. Importing from 'nilearn.input_data' will be possible at least until release 0.13.0. Please import from 'nilearn.maskers' instead.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/e/fmriprep/sub-002/func/sub-002_task-rest_space-MNI152NLin2009cAsym_desc-preproc_bold.nii.gz\n"
     ]
    }
   ],
   "source": [
    "from nilearn import input_data, image\n",
    "\n",
    "# Specify the file paths of the functional and labels (atlas) images\n",
    "func_file = '/mnt/e/fmriprep/sub-002/func/sub-002_task-rest_space-MNI152NLin2009cAsym_desc-preproc_bold.nii.gz'\n",
    "print(func_file)\n",
    "\n",
    "# Load the functional image\n",
    "func_img = image.load_img(func_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: 002, File: /mnt/e/fmriprep/sub-002/func/sub-002_task-rest_space-MNI152NLin2009cAsym_desc-preproc_bold.nii.gz\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "File not found: '/mnt/e/fmriprep/sub-002.html/func/sub-002.html_task-rest_space-MNI152NLin2009cAsym_desc-preproc_bold.nii.gz'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 22\u001b[0m\n\u001b[1;32m     19\u001b[0m func_file \u001b[39m=\u001b[39m base_directory \u001b[39m+\u001b[39m \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39msub-\u001b[39m\u001b[39m{\u001b[39;00msubject\u001b[39m}\u001b[39;00m\u001b[39m/func/sub-\u001b[39m\u001b[39m{\u001b[39;00msubject\u001b[39m}\u001b[39;00m\u001b[39m_task-rest_space-MNI152NLin2009cAsym_desc-preproc_bold.nii.gz\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m     21\u001b[0m \u001b[39m# Load the functional image\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m func_img \u001b[39m=\u001b[39m image\u001b[39m.\u001b[39;49mload_img(func_file)\n\u001b[1;32m     24\u001b[0m \u001b[39m# Process the image as needed\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[39m# ...\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \n\u001b[1;32m     27\u001b[0m \u001b[39m# Print the subject number and file path as an example\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mSubject: \u001b[39m\u001b[39m{\u001b[39;00msubject\u001b[39m}\u001b[39;00m\u001b[39m, File: \u001b[39m\u001b[39m{\u001b[39;00mfunc_file\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/nilearn/image/image.py:1275\u001b[0m, in \u001b[0;36mload_img\u001b[0;34m(img, wildcards, dtype)\u001b[0m\n\u001b[1;32m   1239\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload_img\u001b[39m(img, wildcards\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m   1240\u001b[0m     \u001b[39m\"\"\"Load a Niimg-like object from filenames or list of filenames.\u001b[39;00m\n\u001b[1;32m   1241\u001b[0m \n\u001b[1;32m   1242\u001b[0m \u001b[39m    .. versionadded:: 0.2.5\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1273\u001b[0m \n\u001b[1;32m   1274\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1275\u001b[0m     \u001b[39mreturn\u001b[39;00m check_niimg(img, wildcards\u001b[39m=\u001b[39;49mwildcards, dtype\u001b[39m=\u001b[39;49mdtype)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/nilearn/_utils/niimg_conversions.py:274\u001b[0m, in \u001b[0;36mcheck_niimg\u001b[0;34m(niimg, ensure_ndim, atleast_4d, dtype, return_iterator, wildcards)\u001b[0m\n\u001b[1;32m    272\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(message)\n\u001b[1;32m    273\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 274\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mFile not found: \u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m niimg)\n\u001b[1;32m    275\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexists(niimg):\n\u001b[1;32m    276\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mFile not found: \u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m niimg)\n",
      "\u001b[0;31mValueError\u001b[0m: File not found: '/mnt/e/fmriprep/sub-002.html/func/sub-002.html_task-rest_space-MNI152NLin2009cAsym_desc-preproc_bold.nii.gz'"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "from nilearn import input_data, image\n",
    "\n",
    "# Specify the base directory path where the files are located\n",
    "base_directory = '/mnt/e/fmriprep/'\n",
    "\n",
    "# Specify the pattern of the file names for the functional images\n",
    "func_pattern = 'sub-*'\n",
    "\n",
    "# Find all subdirectories that match the pattern\n",
    "sub_dirs = glob.glob(base_directory + func_pattern)\n",
    "\n",
    "# Extract the subject numbers from the subdirectory paths\n",
    "subject_numbers = [sub_dir.split('-')[1] for sub_dir in sub_dirs]\n",
    "\n",
    "# Loop over the subject numbers and process the files\n",
    "for subject in subject_numbers:\n",
    "    # Construct the file path using the subject number\n",
    "    func_file = base_directory + f'sub-{subject}/func/sub-{subject}_task-rest_space-MNI152NLin2009cAsym_desc-preproc_bold.nii.gz'\n",
    "    \n",
    "    # Load the functional image\n",
    "    func_img = image.load_img(func_file)\n",
    "    \n",
    "    # Process the image as needed\n",
    "    # ...\n",
    "\n",
    "    # Print the subject number and file path as an example\n",
    "    print(f\"Subject: {subject}, File: {func_file}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define ROIs using pain matrix\n",
    "For pain matrix, I focus on six regions: the thalamus, insular cortex (IC), primary and secondary somatosensory cortices (SI and SII), anterior cingulate cortex (ACC), and prefrontal cortex (PFC) (Morton et al., 2016)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 1 Region: Precentral_L\n",
      "Label: 2 Region: Precentral_R\n",
      "Label: 3 Region: Frontal_Sup_L\n",
      "Label: 4 Region: Frontal_Sup_R\n",
      "Label: 5 Region: Frontal_Sup_Orb_L\n",
      "Label: 6 Region: Frontal_Sup_Orb_R\n",
      "Label: 7 Region: Frontal_Mid_L\n",
      "Label: 8 Region: Frontal_Mid_R\n",
      "Label: 9 Region: Frontal_Mid_Orb_L\n",
      "Label: 10 Region: Frontal_Mid_Orb_R\n",
      "Label: 11 Region: Frontal_Inf_Oper_L\n",
      "Label: 12 Region: Frontal_Inf_Oper_R\n",
      "Label: 13 Region: Frontal_Inf_Tri_L\n",
      "Label: 14 Region: Frontal_Inf_Tri_R\n",
      "Label: 15 Region: Frontal_Inf_Orb_L\n",
      "Label: 16 Region: Frontal_Inf_Orb_R\n",
      "Label: 17 Region: Rolandic_Oper_L\n",
      "Label: 18 Region: Rolandic_Oper_R\n",
      "Label: 19 Region: Supp_Motor_Area_L\n",
      "Label: 20 Region: Supp_Motor_Area_R\n",
      "Label: 21 Region: Olfactory_L\n",
      "Label: 22 Region: Olfactory_R\n",
      "Label: 23 Region: Frontal_Sup_Medial_L\n",
      "Label: 24 Region: Frontal_Sup_Medial_R\n",
      "Label: 25 Region: Frontal_Med_Orb_L\n",
      "Label: 26 Region: Frontal_Med_Orb_R\n",
      "Label: 27 Region: Rectus_L\n",
      "Label: 28 Region: Rectus_R\n",
      "Label: 29 Region: Insula_L\n",
      "Label: 30 Region: Insula_R\n",
      "Label: 31 Region: Cingulum_Ant_L\n",
      "Label: 32 Region: Cingulum_Ant_R\n",
      "Label: 33 Region: Cingulum_Mid_L\n",
      "Label: 34 Region: Cingulum_Mid_R\n",
      "Label: 35 Region: Cingulum_Post_L\n",
      "Label: 36 Region: Cingulum_Post_R\n",
      "Label: 37 Region: Hippocampus_L\n",
      "Label: 38 Region: Hippocampus_R\n",
      "Label: 39 Region: ParaHippocampal_L\n",
      "Label: 40 Region: ParaHippocampal_R\n",
      "Label: 41 Region: Amygdala_L\n",
      "Label: 42 Region: Amygdala_R\n",
      "Label: 43 Region: Calcarine_L\n",
      "Label: 44 Region: Calcarine_R\n",
      "Label: 45 Region: Cuneus_L\n",
      "Label: 46 Region: Cuneus_R\n",
      "Label: 47 Region: Lingual_L\n",
      "Label: 48 Region: Lingual_R\n",
      "Label: 49 Region: Occipital_Sup_L\n",
      "Label: 50 Region: Occipital_Sup_R\n",
      "Label: 51 Region: Occipital_Mid_L\n",
      "Label: 52 Region: Occipital_Mid_R\n",
      "Label: 53 Region: Occipital_Inf_L\n",
      "Label: 54 Region: Occipital_Inf_R\n",
      "Label: 55 Region: Fusiform_L\n",
      "Label: 56 Region: Fusiform_R\n",
      "Label: 57 Region: Postcentral_L\n",
      "Label: 58 Region: Postcentral_R\n",
      "Label: 59 Region: Parietal_Sup_L\n",
      "Label: 60 Region: Parietal_Sup_R\n",
      "Label: 61 Region: Parietal_Inf_L\n",
      "Label: 62 Region: Parietal_Inf_R\n",
      "Label: 63 Region: SupraMarginal_L\n",
      "Label: 64 Region: SupraMarginal_R\n",
      "Label: 65 Region: Angular_L\n",
      "Label: 66 Region: Angular_R\n",
      "Label: 67 Region: Precuneus_L\n",
      "Label: 68 Region: Precuneus_R\n",
      "Label: 69 Region: Paracentral_Lobule_L\n",
      "Label: 70 Region: Paracentral_Lobule_R\n",
      "Label: 71 Region: Caudate_L\n",
      "Label: 72 Region: Caudate_R\n",
      "Label: 73 Region: Putamen_L\n",
      "Label: 74 Region: Putamen_R\n",
      "Label: 75 Region: Pallidum_L\n",
      "Label: 76 Region: Pallidum_R\n",
      "Label: 77 Region: Thalamus_L\n",
      "Label: 78 Region: Thalamus_R\n",
      "Label: 79 Region: Heschl_L\n",
      "Label: 80 Region: Heschl_R\n",
      "Label: 81 Region: Temporal_Sup_L\n",
      "Label: 82 Region: Temporal_Sup_R\n",
      "Label: 83 Region: Temporal_Pole_Sup_L\n",
      "Label: 84 Region: Temporal_Pole_Sup_R\n",
      "Label: 85 Region: Temporal_Mid_L\n",
      "Label: 86 Region: Temporal_Mid_R\n",
      "Label: 87 Region: Temporal_Pole_Mid_L\n",
      "Label: 88 Region: Temporal_Pole_Mid_R\n",
      "Label: 89 Region: Temporal_Inf_L\n",
      "Label: 90 Region: Temporal_Inf_R\n",
      "Label: 91 Region: Cerebelum_Crus1_L\n",
      "Label: 92 Region: Cerebelum_Crus1_R\n",
      "Label: 93 Region: Cerebelum_Crus2_L\n",
      "Label: 94 Region: Cerebelum_Crus2_R\n",
      "Label: 95 Region: Cerebelum_3_L\n",
      "Label: 96 Region: Cerebelum_3_R\n",
      "Label: 97 Region: Cerebelum_4_5_L\n",
      "Label: 98 Region: Cerebelum_4_5_R\n",
      "Label: 99 Region: Cerebelum_6_L\n",
      "Label: 100 Region: Cerebelum_6_R\n",
      "Label: 101 Region: Cerebelum_7b_L\n",
      "Label: 102 Region: Cerebelum_7b_R\n",
      "Label: 103 Region: Cerebelum_8_L\n",
      "Label: 104 Region: Cerebelum_8_R\n",
      "Label: 105 Region: Cerebelum_9_L\n",
      "Label: 106 Region: Cerebelum_9_R\n",
      "Label: 107 Region: Cerebelum_10_L\n",
      "Label: 108 Region: Cerebelum_10_R\n",
      "Label: 109 Region: Vermis_1_2\n",
      "Label: 110 Region: Vermis_3\n",
      "Label: 111 Region: Vermis_4_5\n",
      "Label: 112 Region: Vermis_6\n",
      "Label: 113 Region: Vermis_7\n",
      "Label: 114 Region: Vermis_8\n",
      "Label: 115 Region: Vermis_9\n",
      "Label: 116 Region: Vermis_10\n"
     ]
    }
   ],
   "source": [
    "# Access the label values and region names\n",
    "labels = aal_atlas.labels\n",
    "for i, region in enumerate(labels):\n",
    "    print(\"Label:\", i + 1, \"Region:\", region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Region: Postcentral_L, Label number: 57\n",
      "Region: Postcentral_R, Label number: 58\n"
     ]
    }
   ],
   "source": [
    "# Find regions that start with \"Fron\" and retrieve their label numbers\n",
    "target_prefix = \"Postcen\"\n",
    "regions = []\n",
    "numbers = []\n",
    "for i, region in enumerate(aal_atlas.labels):\n",
    "    if region.startswith(target_prefix):\n",
    "        numbers.append(i + 1)\n",
    "        regions.append(region)\n",
    "\n",
    "if regions:\n",
    "    for region, number in zip(regions, numbers):\n",
    "        print(f\"Region: {region}, Label number: {number}\")\n",
    "else:\n",
    "    print(f\"No regions found starting with '{target_prefix}'.\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Region: Thalamus_L, Label number: 77 <br>\n",
    "Region: Thalamus_R, Label number: 78 <br>\n",
    "Region: Insula_L, Label number: 29 <br>\n",
    "Region: Insula_R, Label number: 30 <br>\n",
    "Region: Cingulum_Ant_L, Label number: 31 <br>\n",
    "Region: Cingulum_Ant_R, Label number: 32 <br>\n",
    "Region: Frontal_Inf_Tri_L, Label number: 13 <br>\n",
    "Region: Frontal_Inf_Tri_R, Label number: 14 <br>\n",
    "Region: Precentral_L, Label number: 1 <br>\n",
    "Region: Precentral_R, Label number: 2 <br>\n",
    "Region: Postcentral_L, Label number: 57 <br>\n",
    "Region: Postcentral_R, Label number: 58"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300, 116)\n"
     ]
    }
   ],
   "source": [
    "from nilearn import input_data, image\n",
    "\n",
    "# Define the target region labels as a list\n",
    "target_labels = [1,2,13,14,29,30,31,32,57,58,77,78]  # Replace with your desired label numbers\n",
    "\n",
    "# Filter the AAL atlas labels using the target labels\n",
    "target_regions = [region for region in aal_atlas.labels if any(str(label) in region for label in target_labels)]\n",
    "\n",
    "# Create a masker for the target regions\n",
    "masker = input_data.NiftiLabelsMasker(labels_img=aal_atlas.maps, labels=target_regions, detrend=True, standardize=True, smoothing_fwhm=6.0, high_pass=0.01, low_pass=0.1, t_r=2.0)\n",
    "\n",
    "# Apply the masker to the functional image\n",
    "time_series = masker.fit_transform(func_img)\n",
    "\n",
    "# The resulting time series will contain data only for the target regions\n",
    "print(time_series.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f1b26da6bf0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "thresholded_masked_data = time_series * (time_series > time_series.mean()) \n",
    "#This effectively thresholds the data to remove any low-amplitude noise.\n",
    "\n",
    "thresholded_img = masker.inverse_transform(thresholded_masked_data)\n",
    "#(thresholded_masked_data is a 2D numpy array of the fMRI data after applying a threshold to it. The masker.inverse_transform method is then used to convert the thresholded data into a 3D Nifti image object, where each voxel in the image has the same value as its corresponding voxel in thresholded_masked_data.)\n",
    "\n",
    "plt.imshow(thresholded_img.get_fdata()[:,:,25,0], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       dvars  framewise_displacement   trans_x   trans_y   trans_z     rot_x  \\\n",
      "0        NaN                     NaN -0.030209 -0.042646 -0.060922  0.000203   \n",
      "1  27.229527                0.067177 -0.030247 -0.006518 -0.068794  0.000327   \n",
      "2  23.595106                0.080535 -0.028200 -0.034991 -0.048727  0.000158   \n",
      "3  29.169474                0.052365 -0.030210 -0.007842 -0.051131  0.000229   \n",
      "4  28.552750                0.064280 -0.030240 -0.027970 -0.057058  0.000054   \n",
      "\n",
      "      rot_y     rot_z  \n",
      "0  0.000562  0.000526  \n",
      "1  0.000224  0.000526  \n",
      "2  0.000398  0.000271  \n",
      "3  0.000625  0.000389  \n",
      "4  0.000181  0.000244  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Specify the path(s) of the confound file(s)\n",
    "confound_files = '/mnt/e/fmriprep/sub-002/func/sub-002_task-rest_desc-confounds_timeseries.tsv'\n",
    "\n",
    "# Specify the columns you want to select\n",
    "selected_columns = ['dvars', 'framewise_displacement', 'trans_x','trans_y','trans_z', 'rot_x', 'rot_y', 'rot_z']  # Replace with the names of the columns you want to select\n",
    "\n",
    "# Read the TSV file into a pandas DataFrame\n",
    "df = pd.read_csv(confound_files, delimiter='\\t')\n",
    "\n",
    "# Select only the specified columns\n",
    "selected_df = df[selected_columns]\n",
    "\n",
    "# Now `selected_df` contains the DataFrame with only the selected columns\n",
    "print(selected_df.head())  # Print the first few rows of the selected DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "array must not contain infs or NaNs",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Apply the masker to the functional image\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m time_series \u001b[39m=\u001b[39m masker\u001b[39m.\u001b[39;49mfit_transform(func_img, confounds\u001b[39m=\u001b[39;49mconfound_files)\n\u001b[1;32m      4\u001b[0m \u001b[39m# The resulting time series is a 2D array with shape (n_samples, n_regions)\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[39mprint\u001b[39m(time_series\u001b[39m.\u001b[39mshape)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/sklearn/utils/_set_output.py:142\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[1;32m    141\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 142\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39;49m, X, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    143\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[1;32m    144\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    145\u001b[0m         \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m    146\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[1;32m    147\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[1;32m    148\u001b[0m         )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/nilearn/maskers/nifti_labels_masker.py:488\u001b[0m, in \u001b[0;36mNiftiLabelsMasker.fit_transform\u001b[0;34m(self, imgs, confounds, sample_mask)\u001b[0m\n\u001b[1;32m    457\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit_transform\u001b[39m(\u001b[39mself\u001b[39m, imgs, confounds\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, sample_mask\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    458\u001b[0m     \u001b[39m\"\"\"Prepare and perform signal extraction from regions.\u001b[39;00m\n\u001b[1;32m    459\u001b[0m \n\u001b[1;32m    460\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    486\u001b[0m \n\u001b[1;32m    487\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 488\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit()\u001b[39m.\u001b[39;49mtransform(imgs, confounds\u001b[39m=\u001b[39;49mconfounds,\n\u001b[1;32m    489\u001b[0m                                 sample_mask\u001b[39m=\u001b[39;49msample_mask)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/sklearn/utils/_set_output.py:142\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[1;32m    141\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 142\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39;49m, X, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    143\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[1;32m    144\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    145\u001b[0m         \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m    146\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[1;32m    147\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[1;32m    148\u001b[0m         )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/nilearn/maskers/base_masker.py:249\u001b[0m, in \u001b[0;36mBaseMasker.transform\u001b[0;34m(self, imgs, confounds, sample_mask)\u001b[0m\n\u001b[1;32m    246\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    247\u001b[0m         all_confounds\u001b[39m.\u001b[39mappend(confounds)\n\u001b[0;32m--> 249\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransform_single_imgs(imgs, confounds\u001b[39m=\u001b[39;49mall_confounds,\n\u001b[1;32m    250\u001b[0m                                   sample_mask\u001b[39m=\u001b[39;49msample_mask)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/nilearn/maskers/nifti_labels_masker.py:617\u001b[0m, in \u001b[0;36mNiftiLabelsMasker.transform_single_imgs\u001b[0;34m(self, imgs, confounds, sample_mask)\u001b[0m\n\u001b[1;32m    614\u001b[0m params[\u001b[39m'\u001b[39m\u001b[39mtarget_shape\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m target_shape\n\u001b[1;32m    615\u001b[0m params[\u001b[39m'\u001b[39m\u001b[39mtarget_affine\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m target_affine\n\u001b[0;32m--> 617\u001b[0m region_signals, labels_ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_cache(\n\u001b[1;32m    618\u001b[0m     _filter_and_extract,\n\u001b[1;32m    619\u001b[0m     ignore\u001b[39m=\u001b[39;49m[\u001b[39m'\u001b[39;49m\u001b[39mverbose\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mmemory\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mmemory_level\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    620\u001b[0m )(\n\u001b[1;32m    621\u001b[0m     \u001b[39m# Images\u001b[39;49;00m\n\u001b[1;32m    622\u001b[0m     imgs, _ExtractionFunctor(\n\u001b[1;32m    623\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_resampled_labels_img_,\n\u001b[1;32m    624\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbackground_label,\n\u001b[1;32m    625\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstrategy,\n\u001b[1;32m    626\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_resampled_mask_img,\n\u001b[1;32m    627\u001b[0m     ),\n\u001b[1;32m    628\u001b[0m     \u001b[39m# Pre-processing\u001b[39;49;00m\n\u001b[1;32m    629\u001b[0m     params,\n\u001b[1;32m    630\u001b[0m     confounds\u001b[39m=\u001b[39;49mconfounds,\n\u001b[1;32m    631\u001b[0m     sample_mask\u001b[39m=\u001b[39;49msample_mask,\n\u001b[1;32m    632\u001b[0m     dtype\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdtype,\n\u001b[1;32m    633\u001b[0m     \u001b[39m# Caching\u001b[39;49;00m\n\u001b[1;32m    634\u001b[0m     memory\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmemory,\n\u001b[1;32m    635\u001b[0m     memory_level\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmemory_level,\n\u001b[1;32m    636\u001b[0m     verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[1;32m    637\u001b[0m )\n\u001b[1;32m    639\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlabels_ \u001b[39m=\u001b[39m labels_\n\u001b[1;32m    641\u001b[0m \u001b[39mreturn\u001b[39;00m region_signals\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/joblib/memory.py:349\u001b[0m, in \u001b[0;36mNotMemorizedFunc.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 349\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunc(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/nilearn/maskers/base_masker.py:125\u001b[0m, in \u001b[0;36m_filter_and_extract\u001b[0;34m(imgs, extraction_function, parameters, memory_level, memory, verbose, confounds, sample_mask, copy, dtype)\u001b[0m\n\u001b[1;32m    123\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m[\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m] Cleaning extracted signals\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m class_name)\n\u001b[1;32m    124\u001b[0m runs \u001b[39m=\u001b[39m parameters\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mruns\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[0;32m--> 125\u001b[0m region_signals \u001b[39m=\u001b[39m cache(\n\u001b[1;32m    126\u001b[0m     signal\u001b[39m.\u001b[39;49mclean, memory\u001b[39m=\u001b[39;49mmemory, func_memory_level\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m,\n\u001b[1;32m    127\u001b[0m     memory_level\u001b[39m=\u001b[39;49mmemory_level)(\n\u001b[1;32m    128\u001b[0m         region_signals,\n\u001b[1;32m    129\u001b[0m         detrend\u001b[39m=\u001b[39;49mparameters[\u001b[39m'\u001b[39;49m\u001b[39mdetrend\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    130\u001b[0m         standardize\u001b[39m=\u001b[39;49mparameters[\u001b[39m'\u001b[39;49m\u001b[39mstandardize\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    131\u001b[0m         standardize_confounds\u001b[39m=\u001b[39;49mparameters[\u001b[39m'\u001b[39;49m\u001b[39mstandardize_confounds\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    132\u001b[0m         t_r\u001b[39m=\u001b[39;49mparameters[\u001b[39m'\u001b[39;49m\u001b[39mt_r\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    133\u001b[0m         low_pass\u001b[39m=\u001b[39;49mparameters[\u001b[39m'\u001b[39;49m\u001b[39mlow_pass\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    134\u001b[0m         high_pass\u001b[39m=\u001b[39;49mparameters[\u001b[39m'\u001b[39;49m\u001b[39mhigh_pass\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    135\u001b[0m         confounds\u001b[39m=\u001b[39;49mconfounds,\n\u001b[1;32m    136\u001b[0m         sample_mask\u001b[39m=\u001b[39;49msample_mask,\n\u001b[1;32m    137\u001b[0m         runs\u001b[39m=\u001b[39;49mruns)\n\u001b[1;32m    139\u001b[0m \u001b[39mreturn\u001b[39;00m region_signals, aux\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/joblib/memory.py:349\u001b[0m, in \u001b[0;36mNotMemorizedFunc.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 349\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunc(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/nilearn/signal.py:669\u001b[0m, in \u001b[0;36mclean\u001b[0;34m(signals, runs, detrend, standardize, sample_mask, confounds, standardize_confounds, filter, low_pass, high_pass, t_r, ensure_finite)\u001b[0m\n\u001b[1;32m    666\u001b[0m     confounds \u001b[39m/\u001b[39m\u001b[39m=\u001b[39m confound_max\n\u001b[1;32m    668\u001b[0m \u001b[39m# Pivoting in qr decomposition was added in scipy 0.10\u001b[39;00m\n\u001b[0;32m--> 669\u001b[0m Q, R, _ \u001b[39m=\u001b[39m linalg\u001b[39m.\u001b[39;49mqr(confounds, mode\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39meconomic\u001b[39;49m\u001b[39m'\u001b[39;49m, pivoting\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m    670\u001b[0m Q \u001b[39m=\u001b[39m Q[:, np\u001b[39m.\u001b[39mabs(np\u001b[39m.\u001b[39mdiag(R)) \u001b[39m>\u001b[39m np\u001b[39m.\u001b[39mfinfo(np\u001b[39m.\u001b[39mfloat64)\u001b[39m.\u001b[39meps \u001b[39m*\u001b[39m \u001b[39m100.\u001b[39m]\n\u001b[1;32m    671\u001b[0m signals \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m Q\u001b[39m.\u001b[39mdot(Q\u001b[39m.\u001b[39mT)\u001b[39m.\u001b[39mdot(signals)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/scipy/linalg/_decomp_qr.py:128\u001b[0m, in \u001b[0;36mqr\u001b[0;34m(a, overwrite_a, lwork, mode, pivoting, check_finite)\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mMode argument should be one of [\u001b[39m\u001b[39m'\u001b[39m\u001b[39mfull\u001b[39m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    125\u001b[0m                      \u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39meconomic\u001b[39m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39mraw\u001b[39m\u001b[39m'\u001b[39m\u001b[39m]\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    127\u001b[0m \u001b[39mif\u001b[39;00m check_finite:\n\u001b[0;32m--> 128\u001b[0m     a1 \u001b[39m=\u001b[39m numpy\u001b[39m.\u001b[39;49masarray_chkfinite(a)\n\u001b[1;32m    129\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    130\u001b[0m     a1 \u001b[39m=\u001b[39m numpy\u001b[39m.\u001b[39masarray(a)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/numpy/lib/function_base.py:627\u001b[0m, in \u001b[0;36masarray_chkfinite\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    625\u001b[0m a \u001b[39m=\u001b[39m asarray(a, dtype\u001b[39m=\u001b[39mdtype, order\u001b[39m=\u001b[39morder)\n\u001b[1;32m    626\u001b[0m \u001b[39mif\u001b[39;00m a\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mchar \u001b[39min\u001b[39;00m typecodes[\u001b[39m'\u001b[39m\u001b[39mAllFloat\u001b[39m\u001b[39m'\u001b[39m] \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m np\u001b[39m.\u001b[39misfinite(a)\u001b[39m.\u001b[39mall():\n\u001b[0;32m--> 627\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    628\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39marray must not contain infs or NaNs\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    629\u001b[0m \u001b[39mreturn\u001b[39;00m a\n",
      "\u001b[0;31mValueError\u001b[0m: array must not contain infs or NaNs"
     ]
    }
   ],
   "source": [
    "# Apply the masker to the functional image\n",
    "time_series = masker.fit_transform(func_img, confounds=confound_files)\n",
    "\n",
    "# The resulting time series is a 2D array with shape (n_samples, n_regions)\n",
    "print(time_series.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
